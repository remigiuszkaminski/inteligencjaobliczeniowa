{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praca Domowa nr 2 Remigiusz Kamiński"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wstęp:\n",
    "\n",
    "W tej pracy domowej zajme się zestawem danych mówiącym o cenach domów w stanie California w Stanach Zjednoczonych Ameryki. Dane są z roku 1990. Przedstawiają ilość pokoi, ludzi, i tak dalej na podstawie bloków jakby na mapie. Baza sama w sobie jest dosyć rozbudowana, gdyż posiada ponad 20000 wierszy oraz 10 kolumn.\n",
    "\n",
    "Możemy spojrzeć na mały wycinek danych przed preprocessingiem:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value,ocean_proximity\n",
    "\n",
    "-122.23,37.88,41.0,880.0,129.0,322.0,126.0,8.3252,452600.0,NEAR BAY\n",
    "\n",
    "-122.22,37.86,21.0,7099.0,1106.0,2401.0,1138.0,8.3014,358500.0,NEAR BAY\n",
    "\n",
    "-122.24,37.85,52.0,1467.0,190.0,496.0,177.0,7.2574,352100.0,NEAR BAY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać są tutaj podane przykładowe dane, warto dodać iż każdy jeden wiersz odpowiada jednemu blokowi.\n",
    "Następnie zajmiemy się kolejnym zagadnieniem czyli prepocessingiem:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli chodzi o preprocessing w naszych danych i w 1 i w 2 wersji zamieniłem mediane ceny na przedziały wartości zmieniające się co 50000 dolarów. Niestety baza danych jest dosyć kompletna, aczkolwiek zdarzają się w niej puste wartości dlatego w przypadku 1 wersji wstawiam tam po prostu 0, a w przypadku 2 używam funkcji interpolate(), która ma za zadanie wywnioskować jaka wartość mogłaby tam być, czyli po prostu wynik powinien być bardziej dokładny. Aby zatem zauważyć różnice, którą da nam preprocessing w 1 funkcji na dodatek nie skorzystam ze skalowania i normalizacji danych, a w 2 już tak dzięki czemu teoretycznie 2 powinna być bardziej dokładna. Na dodatek zamieniłem string z ocean_proximity na wartość INT przy pomocy funkcji LabelEncoder. Poniżej znajdują się kody preprocessingu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_csv('housing.csv', sep=',', header=0)\n",
    "print(data.columns)\n",
    "label_encoder = LabelEncoder()\n",
    "data['ocean_proximity_encoded'] = label_encoder.fit_transform(data['ocean_proximity'])\n",
    "\n",
    "\n",
    "data = data.fillna(0)\n",
    "bins = [0, 50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 500000, float('inf')]\n",
    "data['median_house_value_category'] = pd.cut(data['median_house_value'], bins=bins, labels=False, right=False)\n",
    "data = data.drop(['median_house_value', 'ocean_proximity'], axis=1)\n",
    "data.to_csv('housing_preprocessed.csv', sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "data = pd.read_csv('housing.csv', sep=',', header=0)\n",
    "print(data.columns)\n",
    "label_encoder = LabelEncoder()\n",
    "data['ocean_proximity_encoded'] = label_encoder.fit_transform(data['ocean_proximity'])\n",
    "for column in data.columns:\n",
    "    data[column] = data[column].interpolate()\n",
    "\n",
    "\n",
    "bins = [0, 50000, 100000, 150000, 200000, 250000, 300000, 350000, 400000, 450000, 500000, float('inf')]\n",
    "data['median_house_value_category'] = pd.cut(data['median_house_value'], bins=bins, labels=False, right=False)\n",
    "data = data.drop(['median_house_value', 'ocean_proximity'], axis=1)\n",
    "data.to_csv('housing_preprocessed2.csv', sep=',',index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po wykonaniu tego preprocessingu, zaczynamy zabawe z podziałem danych na zbiór treningowy oraz testowy. Po wykonaniu tego zadania uczymy algorytmy oraz je testujemy. Do naszej dyspozycji mamy:\n",
    "Drzewo Decyzyjne\n",
    "Naiwnego Bayesa\n",
    "K-najblizszych sasiadow\n",
    "Sieć neuronowa\n",
    "\n",
    "Jeśli chodzi o drzewo decyzyjne użyje wersji mniejszej oraz większej (bardziej przycięte gałęzie). K-najblizszych sasiadów otrzyma różne K, a sieć neuronowa pare topologii.\n",
    "\n",
    "1 część kodu będzie odnosiła się do funkcji mniej przerobionej w preprocessingu, a 2 do tej bardziej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'ocean_proximity_encoded', 'median_house_value_category'],\n",
      "      dtype='object')\n",
      "Dokładnosc dla: DTC small:  0.41569767441860467\n",
      "Dokładnosc dla: DTC large:  0.48594961240310075\n",
      "Dokładnosc dla: NB:  0.32122093023255816\n",
      "Dokładnosc dla: KNN:  0.2238372093023256\n",
      "Dokładnosc dla: KNN2:  0.24200581395348839\n",
      "Dokładnosc dla: KNN3:  0.2374031007751938\n",
      "Dokładnosc dla: MLP:  0.27398255813953487\n",
      "Dokładnosc dla: MLP2:  0.24127906976744187\n",
      "Dokładnosc dla: MLP3:  0.37306201550387597\n",
      "Macierz błędu dla: DTC small:  [[  0  36   4   0   1   0   0   0   0   0   0]\n",
      " [  0 438 206  17   3   5   0   0   0   0   1]\n",
      " [  0 159 426 141  29  34   1   0   0   0   0]\n",
      " [  0  23 260 358 126  89   2   0   0   0   1]\n",
      " [  0   7 104 158 179 124  20   3   0   0   3]\n",
      " [  0   1  43  38 108 141  46   3   0   0   3]\n",
      " [  0   0  24  12  63  70  53   7   0   0  11]\n",
      " [  0   0  16   5  41  51  42  11   0   0  19]\n",
      " [  0   0   4   3  20  25  16   9   0   0  24]\n",
      " [  0   0   8   0   5  11   7   7   0   0   7]\n",
      " [  0   2   9   5  30  35  18   7   0   0 110]]\n",
      "Macierz błędu dla: DTC large:  [[  4  31   1   2   3   0   0   0   0   0   0]\n",
      " [  9 494 145  12   6   0   3   1   0   0   0]\n",
      " [  1 170 429 151  31   2   5   0   0   0   1]\n",
      " [  2  34 184 456 160  19   2   1   0   0   1]\n",
      " [  0   5  44 184 273  63  19   5   3   0   2]\n",
      " [  0   0  17  51 138 116  39  16   3   0   3]\n",
      " [  0   3   6  21  49  63  74  15   2   2   5]\n",
      " [  0   1   2  10  39  25  39  42   3   6  18]\n",
      " [  0   0   0   3  18   8  24  27   1   2  18]\n",
      " [  0   0   2   1  10   0   7  11   4   1   9]\n",
      " [  0   1   3   8  24   6  25  11  12  10 116]]\n",
      "Macierz błędu dla: NB:  [[  0  38   3   0   0   0   0   0   0   0   0]\n",
      " [  0 557  54  53   1   4   0   0   0   0   1]\n",
      " [  2 431  94 210  17  36   0   0   0   0   0]\n",
      " [  0 299  61 388  52  54   0   1   2   0   2]\n",
      " [  0 117  45 262  84  65   0   1  11   0  13]\n",
      " [  0  53  22  93  92  72   2   0  29   0  20]\n",
      " [  0  27   7  58  46  39   2   1  28   0  32]\n",
      " [  0  18   7  36  31  24   1   6  29   0  33]\n",
      " [  0   9   1  19  12  10   0   3  13   0  34]\n",
      " [  0   5   2   7   6   4   0   3   5   0  13]\n",
      " [  0  10   7  35  14  10   0   9  18   3 110]]\n",
      "Macierz błędu dla: KNN:  [[  0  23   7   9   1   1   0   0   0   0   0]\n",
      " [ 18 302 168 119  40  13   3   5   1   0   1]\n",
      " [ 18 287 218 160  65  27   8   4   1   0   2]\n",
      " [ 26 275 218 208  77  33   6   5   2   0   9]\n",
      " [  7 183 149 129  84  23   9   7   1   1   5]\n",
      " [  3  89  94  75  56  37  13   7   1   1   7]\n",
      " [  0  63  37  55  33  27  15   3   2   0   5]\n",
      " [  1  40  34  35  27  20  13   3   0   1  11]\n",
      " [  0  22  17  16   8  14   5   7   2   2   8]\n",
      " [  1   9   9   4   5   6   4   2   1   0   4]\n",
      " [  1  31  26  24  18  20  20   9   9   3  55]]\n",
      "Macierz błędu dla: KNN2:  [[  0  22   6   9   2   1   0   0   0   0   1]\n",
      " [  2 251 182 159  53  12   2   3   0   0   6]\n",
      " [  2 225 247 182  74  35  10   4   1   0  10]\n",
      " [  0 241 214 249  84  36  14  11   1   0   9]\n",
      " [  1 150 131 159  94  34  12   6   1   0  10]\n",
      " [  0  71  76  85  63  42  20   8   4   1  13]\n",
      " [  0  50  36  51  35  28  23   4   0   3  10]\n",
      " [  1  31  28  37  27  21   9  12   1   1  17]\n",
      " [  0  21  13  14  11  11   4   9   2   0  16]\n",
      " [  0   6   5   7   6   6   4   3   2   0   6]\n",
      " [  0  17  23  27  13  15  17  18   6   1  79]]\n",
      "Macierz błędu dla: KNN3:  [[  0  14  12  13   0   1   1   0   0   0   0]\n",
      " [  0 264 162 172  49  11   5   1   0   0   6]\n",
      " [  0 208 231 206  87  32   5   5   0   0  16]\n",
      " [  0 214 238 245  86  39  13  10   2   0  12]\n",
      " [  0 139 133 171  97  25   9   7   0   1  16]\n",
      " [  0  74  81  82  67  40  13   7   2   0  17]\n",
      " [  0  44  37  51  37  31  13   9   1   1  16]\n",
      " [  0  30  29  39  25  22  12  10   0   2  16]\n",
      " [  0  19   8  16   8  11  10   7   1   0  21]\n",
      " [  0   4   3   8   8   6   3   2   1   1   9]\n",
      " [  0  16  24  26  20  18  15  16   1   2  78]]\n",
      "Macierz błędu dla: MLP:  [[  1  25   6   4   1   1   1   0   0   0   2]\n",
      " [  4 387 226  29   4   2   3   1   7   0   7]\n",
      " [  0 236 423  77  17   5   4   1  17   0  10]\n",
      " [  4 129 438 208  15  15   1   0  33   0  16]\n",
      " [  1  66 357  86  19  25   7   0  23   0  14]\n",
      " [  0  28 223  36   9  30   1   0  40   0  16]\n",
      " [  0  15 112  18   9  45   0   0  31   0  10]\n",
      " [  0   8  67  10   4  44   1   0  37   0  14]\n",
      " [  0   2  28   3   5  27   0   0  26   0  10]\n",
      " [  1   3   9   2   0  12   0   1  14   0   3]\n",
      " [  1   4  25   6   7  61   0   0  75   0  37]]\n",
      "Macierz błędu dla: MLP2:  [[  0  34   0   5   1   0   1   0   0   0   0]\n",
      " [  0 554  46  35  20   0   9   0   0   0   6]\n",
      " [  0 558  74  69  59   6  11   1   0   0  12]\n",
      " [  2 581  53  94  77  11  26   1   0   0  14]\n",
      " [  0 370  47  19  90  16  38   3   0   0  15]\n",
      " [  0 162  55   4  56  33  53   1   0   1  18]\n",
      " [  1  76  23   2  34  30  46   2   0   2  24]\n",
      " [  0  44  15   3  15  21  52   3   0   1  31]\n",
      " [  0  14   3   0   9  13  37   4   0   1  20]\n",
      " [  0  11   2   0   0   5  13   2   0   0  12]\n",
      " [  0  16   8   5   7  14  43  16   0   5 102]]\n",
      "Macierz błędu dla: MLP3:  [[  0  34   5   1   0   0   0   0   0   0   1]\n",
      " [  0 440 133  86   5   5   1   0   0   0   0]\n",
      " [  0 219 220 310  28  11   2   0   0   0   0]\n",
      " [  0  70 157 486  94  35   9   0   0   0   8]\n",
      " [  0  25  46 287 128  85  13   0   0   0  14]\n",
      " [  0   7  14 144  77  79  33   1   0   0  28]\n",
      " [  0   4   8  48  46  56  38   2   0   0  38]\n",
      " [  0   3   3  31  23  36  31   0   0   0  58]\n",
      " [  0   0   0   7   9  23  16   0   0   0  46]\n",
      " [  0   1   3   5   4   8   2   0   0   0  22]\n",
      " [  0   2   2  10  16  18  18   1   0   0 149]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "data = pd.read_csv('housing_preprocessed.csv', sep=',', header=0)\n",
    "# data = pd.read_csv('housing_preprocessed2.csv', sep=',', header=0)\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_all = label_encoder.fit_transform(np.concatenate([y_train, y_test]))\n",
    "y_train = y_all[:len(y_train)]\n",
    "y_test = y_all[len(y_train):]\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# normalizer = MinMaxScaler()\n",
    "# normalizer.fit(X_train)\n",
    "# X_train = normalizer.transform(X_train)\n",
    "# X_test = normalizer.transform(X_test)\n",
    "\n",
    "\n",
    "dtc_small = DecisionTreeClassifier(max_depth=5, random_state=1234)\n",
    "dtc_large = DecisionTreeClassifier(max_depth=10, random_state=1234)\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=20)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1500, random_state=1234)\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1500, random_state=1234)\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(20, 10, 5), max_iter=1500, random_state=1234)\n",
    "\n",
    "dtc_small.fit(X_train, y_train)\n",
    "dtc_large.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "knn2.fit(X_train, y_train)\n",
    "knn3.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp2.fit(X_train, y_train)\n",
    "mlp3.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dtc_small = dtc_small.predict(X_test)\n",
    "y_pred_dtc_large = dtc_large.predict(X_test)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_knn2 = knn2.predict(X_test)\n",
    "y_pred_knn3 = knn3.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "y_pred_mlp2 = mlp2.predict(X_test)\n",
    "y_pred_mlp3 = mlp3.predict(X_test)\n",
    "\n",
    "cm_dtc_small = confusion_matrix(y_test, y_pred_dtc_small)\n",
    "cm_dtc_large = confusion_matrix(y_test, y_pred_dtc_large)\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "cm_knn2 = confusion_matrix(y_test, y_pred_knn2)\n",
    "cm_knn3 = confusion_matrix(y_test, y_pred_knn3)\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "cm_mlp2 = confusion_matrix(y_test, y_pred_mlp2)\n",
    "cm_mlp3 = confusion_matrix(y_test, y_pred_mlp3)\n",
    "\n",
    "print('Dokładnosc dla: DTC small: ', accuracy_score(y_test, y_pred_dtc_small))\n",
    "print('Dokładnosc dla: DTC large: ', accuracy_score(y_test, y_pred_dtc_large))\n",
    "print('Dokładnosc dla: NB: ', accuracy_score(y_test, y_pred_nb))\n",
    "print('Dokładnosc dla: KNN: ', accuracy_score(y_test, y_pred_knn))\n",
    "print('Dokładnosc dla: KNN2: ', accuracy_score(y_test, y_pred_knn2))\n",
    "print('Dokładnosc dla: KNN3: ', accuracy_score(y_test, y_pred_knn3))\n",
    "print('Dokładnosc dla: MLP: ', accuracy_score(y_test, y_pred_mlp))\n",
    "print('Dokładnosc dla: MLP2: ', accuracy_score(y_test, y_pred_mlp2))\n",
    "print('Dokładnosc dla: MLP3: ', accuracy_score(y_test, y_pred_mlp3))\n",
    "\n",
    "print('Macierz błędu dla: DTC small: ', cm_dtc_small)\n",
    "print('Macierz błędu dla: DTC large: ', cm_dtc_large)\n",
    "print('Macierz błędu dla: NB: ', cm_nb)\n",
    "print('Macierz błędu dla: KNN: ', cm_knn)\n",
    "print('Macierz błędu dla: KNN2: ', cm_knn2)\n",
    "print('Macierz błędu dla: KNN3: ', cm_knn3)\n",
    "print('Macierz błędu dla: MLP: ', cm_mlp)\n",
    "print('Macierz błędu dla: MLP2: ', cm_mlp2)\n",
    "print('Macierz błędu dla: MLP3: ', cm_mlp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'ocean_proximity_encoded', 'median_house_value_category'],\n",
      "      dtype='object')\n",
      "Dokładnosc dla: DTC small:  0.41569767441860467\n",
      "Dokładnosc dla: DTC large:  0.4844961240310077\n",
      "Dokładnosc dla: NB:  0.3224321705426357\n",
      "Dokładnosc dla: KNN:  0.4176356589147287\n",
      "Dokładnosc dla: KNN2:  0.44476744186046513\n",
      "Dokładnosc dla: KNN3:  0.4471899224806202\n",
      "Dokładnosc dla: MLP:  0.4639050387596899\n",
      "Dokładnosc dla: MLP2:  0.4530038759689923\n",
      "Dokładnosc dla: MLP3:  0.4745639534883721\n",
      "Macierz błędu dla: DTC small:  [[  0  36   4   0   1   0   0   0   0   0   0]\n",
      " [  0 438 206  17   3   5   0   0   0   0   1]\n",
      " [  0 159 426 141  29  34   1   0   0   0   0]\n",
      " [  0  23 260 358 126  89   2   0   0   0   1]\n",
      " [  0   7 104 158 179 124  20   3   0   0   3]\n",
      " [  0   1  43  38 108 141  46   3   0   0   3]\n",
      " [  0   0  24  12  63  70  53   7   0   0  11]\n",
      " [  0   0  16   5  41  51  42  11   0   0  19]\n",
      " [  0   0   4   3  20  25  16   9   0   0  24]\n",
      " [  0   0   8   0   5  11   7   7   0   0   7]\n",
      " [  0   2   9   5  30  35  18   7   0   0 110]]\n",
      "Macierz błędu dla: DTC large:  [[  5  30   1   2   3   0   0   0   0   0   0]\n",
      " [  8 498 139  15   6   0   3   1   0   0   0]\n",
      " [  2 166 430 149  34   3   5   0   0   0   1]\n",
      " [  2  36 183 452 161  21   2   1   0   0   1]\n",
      " [  0   5  41 182 274  67  18   6   3   0   2]\n",
      " [  0   0  17  52 144 111  36  16   4   0   3]\n",
      " [  1   3   6  20  50  63  71  14   5   2   5]\n",
      " [  0   1   2  10  44  25  37  39   3   6  18]\n",
      " [  0   0   0   4  17   9  22  27   2   2  18]\n",
      " [  0   0   2   0  10   1   7  11   4   1   9]\n",
      " [  0   1   3   8  24   7  22  11  13  10 117]]\n",
      "Macierz błędu dla: NB:  [[  0  38   3   0   0   0   0   0   0   0   0]\n",
      " [  0 558  53  53   1   4   0   0   0   0   1]\n",
      " [  2 431  96 208  17  36   0   0   0   0   0]\n",
      " [  0 298  61 388  52  55   0   1   2   0   2]\n",
      " [  0 117  43 263  85  64   0   1  12   0  13]\n",
      " [  0  53  22  91  94  73   2   0  28   0  20]\n",
      " [  0  27   7  58  45  40   2   1  28   0  32]\n",
      " [  0  17   7  36  31  25   1   6  29   0  33]\n",
      " [  0   9   1  19  12  10   0   3  13   0  34]\n",
      " [  0   5   2   7   6   4   0   3   5   0  13]\n",
      " [  0   9   7  35  14  10   0   9  19   3 110]]\n",
      "Macierz błędu dla: KNN:  [[  5  32   3   0   1   0   0   0   0   0   0]\n",
      " [ 13 499 128  26   3   1   0   0   0   0   0]\n",
      " [  2 233 382 144  23   4   1   1   0   0   0]\n",
      " [  2  58 251 394 119  25   5   4   0   0   1]\n",
      " [  1  19  86 216 189  57  18   6   2   0   4]\n",
      " [  1   4  35  82 115 101  29   9   3   1   3]\n",
      " [  0   2  17  40  63  61  37  14   2   3   1]\n",
      " [  0   2  13  18  34  45  35  22   8   2   6]\n",
      " [  0   1   3   8  22  14  15  17   8   4   9]\n",
      " [  0   1   6   3   8   6   4   8   2   1   6]\n",
      " [  0   4  10  13  26  16  13  19  21   8  86]]\n",
      "Macierz błędu dla: KNN2:  [[  1  36   1   1   2   0   0   0   0   0   0]\n",
      " [  5 501 141  16   6   0   0   0   0   0   1]\n",
      " [  0 191 420 152  19   6   2   0   0   0   0]\n",
      " [  0  41 240 440 102  29   2   4   1   0   0]\n",
      " [  0  11  79 226 191  75  11   2   2   0   1]\n",
      " [  0   3  18  92 107 117  28  14   2   1   1]\n",
      " [  0   1   8  44  63  59  37  20   3   0   5]\n",
      " [  0   0  11  18  40  46  26  27   8   4   5]\n",
      " [  0   0   1   6  20  20  17  18   5   2  12]\n",
      " [  0   0   2   7  11   6   5   6   0   2   6]\n",
      " [  0   4   5  15  26  19  11  20  13   8  95]]\n",
      "Macierz błędu dla: KNN3:  [[  0  37   2   1   1   0   0   0   0   0   0]\n",
      " [  0 507 138  21   3   0   0   0   0   0   1]\n",
      " [  0 185 422 153  22   7   1   0   0   0   0]\n",
      " [  0  36 240 450 109  21   2   0   0   0   1]\n",
      " [  0   8  83 238 193  60   8   6   1   0   1]\n",
      " [  0   1  29  98 107 112  21  11   1   2   1]\n",
      " [  0   0  13  44  58  71  31  13   4   2   4]\n",
      " [  0   2  11  14  45  51  20  23   6   1  12]\n",
      " [  0   0   1  10  22  21   7  18   9   0  13]\n",
      " [  0   0   3   6  11   5   3   6   1   0  10]\n",
      " [  0   3   4  23  29  16  14  16   7   5  99]]\n",
      "Macierz błędu dla: MLP:  [[  0  35   5   1   0   0   0   0   0   0   0]\n",
      " [  0 507 129  31   1   0   0   0   0   0   2]\n",
      " [  0 203 332 232  20   2   0   0   0   0   1]\n",
      " [  0  49 154 522 115  17   1   0   0   0   1]\n",
      " [  0  14  38 240 246  47   5   3   0   0   5]\n",
      " [  0   2   8  79 150 111  16  14   0   0   3]\n",
      " [  0   2   3  25  82  73  21  19   0   0  15]\n",
      " [  0   0   3  18  39  42  12  27   0   0  44]\n",
      " [  0   0   0   4  18  20   6  22   0   0  31]\n",
      " [  0   2   0   4   8   5   3   8   0   0  15]\n",
      " [  0   3   1   9  22  17   5  10   0   0 149]]\n",
      "Macierz błędu dla: MLP2:  [[  0  34   5   1   0   0   0   0   0   0   1]\n",
      " [  0 488 144  32   2   0   0   0   0   0   4]\n",
      " [  1 192 360 205  26   5   0   0   0   0   1]\n",
      " [  0  35 199 479 111  33   1   0   0   0   1]\n",
      " [  0   8  61 223 211  81   6   2   0   0   6]\n",
      " [  0   3  13  72 119 148  17   6   0   0   5]\n",
      " [  0   0   7  32  52  98  21  10   0   0  20]\n",
      " [  0   0   6  14  32  57  18  18   0   0  40]\n",
      " [  0   0   0   5  10  31   9  15   0   0  31]\n",
      " [  0   2   0   4   5   7   4   2   0   0  21]\n",
      " [  0   3   4   8  16  26   4  10   0   0 145]]\n",
      "Macierz błędu dla: MLP3:  [[  0  38   2   1   0   0   0   0   0   0   0]\n",
      " [  0 510 136  19   4   0   0   0   0   0   1]\n",
      " [  0 161 401 200  20   6   1   0   0   0   1]\n",
      " [  0  30 174 509 114  24   3   3   0   0   2]\n",
      " [  0   7  44 228 211  99   2   2   0   0   5]\n",
      " [  0   1   7  69 130 137  17  16   0   0   6]\n",
      " [  0   1   4  23  48 109  15  20   0   0  20]\n",
      " [  0   1   4  15  26  55  13  31   0   0  40]\n",
      " [  0   0   0   2  11  26   8  23   0   0  31]\n",
      " [  0   0   4   2   4  10   2   3   0   0  20]\n",
      " [  0   3   2   8  13  14  12  19   0   0 145]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# data = pd.read_csv('housing_preprocessed.csv', sep=',', header=0)\n",
    "data = pd.read_csv('housing_preprocessed2.csv', sep=',', header=0)\n",
    "print(data.columns)\n",
    "\n",
    "\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_all = label_encoder.fit_transform(np.concatenate([y_train, y_test]))\n",
    "y_train = y_all[:len(y_train)]\n",
    "y_test = y_all[len(y_train):]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(X_train)\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "\n",
    "\n",
    "dtc_small = DecisionTreeClassifier(max_depth=5, random_state=1234)\n",
    "dtc_large = DecisionTreeClassifier(max_depth=10, random_state=1234)\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=20)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1500, random_state=1234)\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1500, random_state=1234)\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(20, 10, 5), max_iter=1500, random_state=1234)\n",
    "\n",
    "dtc_small.fit(X_train, y_train)\n",
    "dtc_large.fit(X_train, y_train)\n",
    "nb.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "knn2.fit(X_train, y_train)\n",
    "knn3.fit(X_train, y_train)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp2.fit(X_train, y_train)\n",
    "mlp3.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dtc_small = dtc_small.predict(X_test)\n",
    "y_pred_dtc_large = dtc_large.predict(X_test)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_knn2 = knn2.predict(X_test)\n",
    "y_pred_knn3 = knn3.predict(X_test)\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "y_pred_mlp2 = mlp2.predict(X_test)\n",
    "y_pred_mlp3 = mlp3.predict(X_test)\n",
    "\n",
    "cm_dtc_small = confusion_matrix(y_test, y_pred_dtc_small)\n",
    "cm_dtc_large = confusion_matrix(y_test, y_pred_dtc_large)\n",
    "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "cm_knn2 = confusion_matrix(y_test, y_pred_knn2)\n",
    "cm_knn3 = confusion_matrix(y_test, y_pred_knn3)\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "cm_mlp2 = confusion_matrix(y_test, y_pred_mlp2)\n",
    "cm_mlp3 = confusion_matrix(y_test, y_pred_mlp3)\n",
    "\n",
    "print('Dokładnosc dla: DTC small: ', accuracy_score(y_test, y_pred_dtc_small))\n",
    "print('Dokładnosc dla: DTC large: ', accuracy_score(y_test, y_pred_dtc_large))\n",
    "print('Dokładnosc dla: NB: ', accuracy_score(y_test, y_pred_nb))\n",
    "print('Dokładnosc dla: KNN: ', accuracy_score(y_test, y_pred_knn))\n",
    "print('Dokładnosc dla: KNN2: ', accuracy_score(y_test, y_pred_knn2))\n",
    "print('Dokładnosc dla: KNN3: ', accuracy_score(y_test, y_pred_knn3))\n",
    "print('Dokładnosc dla: MLP: ', accuracy_score(y_test, y_pred_mlp))\n",
    "print('Dokładnosc dla: MLP2: ', accuracy_score(y_test, y_pred_mlp2))\n",
    "print('Dokładnosc dla: MLP3: ', accuracy_score(y_test, y_pred_mlp3))\n",
    "\n",
    "print('Macierz błędu dla: DTC small: ', cm_dtc_small)\n",
    "print('Macierz błędu dla: DTC large: ', cm_dtc_large)\n",
    "print('Macierz błędu dla: NB: ', cm_nb)\n",
    "print('Macierz błędu dla: KNN: ', cm_knn)\n",
    "print('Macierz błędu dla: KNN2: ', cm_knn2)\n",
    "print('Macierz błędu dla: KNN3: ', cm_knn3)\n",
    "print('Macierz błędu dla: MLP: ', cm_mlp)\n",
    "print('Macierz błędu dla: MLP2: ', cm_mlp2)\n",
    "print('Macierz błędu dla: MLP3: ', cm_mlp3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli spojrzymy na otrzymane wyniki, od razu możemy dostrzec iż nie różnią się one znacząco jeśli chodzi o Drzewo decyzyjne czy też naiwnego bayesa, ale za to jeśli chodzi k-najbliższych sąsiadów i sieć neuronową to bez 2 zdań miało to tutaj znaczenie, aby lepiej to zobaczyć umieszczę wyniki na wykresie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "funkcja1 = [0.41569767441860467, 0.48594961240310075, 0.32122093023255816, 0.2238372093023256, 0.24200581395348839, 0.2374031007751938, 0.27398255813953487, 0.24127906976744187, 0.37306201550387597]\n",
    "funckja2 = [0.41569767441860467, 0.4844961240310077, 0.3224321705426357, 0.4176356589147287, 0.44476744186046513, 0.4471899224806202, 0.4639050387596899, 0.4530038759689923, 0.4745639534883721]\n",
    "\n",
    "klasy = ['DTC small', 'DTC large', 'NB', 'KNN', 'KNN2', 'KNN3', 'MLP', 'MLP2', 'MLP3']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(klasy))\n",
    "width = 0.35\n",
    "rects1 = ax.bar(x - width/2, funkcja1, width, label='funkcja 1', alpha=0.8)\n",
    "rects2 = ax.bar(x + width/2, funckja2, width, label='funkcja 2', alpha=0.5)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(klasy)\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Małe podsumowanie:\n",
    "\n",
    "Jak widzimy na tym wykresie nasz mocniejszy preprocessing dał duży wzrost procentowy jeśli chodzi o dokładne wyniki dla k-n sąsiadów jak i sieci neuronowych, również widać iż różne k czy też różna topologia, wpływa na dokładność, gdyż różni się ona dla tych klasyfikatorów."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
